{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a joint LSTM on all signals simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0929 17:26:25.804311 139970483787584 deprecation_wrapper.py:119] From ../embedding_utils.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0929 17:26:25.806766 139970483787584 deprecation_wrapper.py:119] From ../embedding_utils.py:16: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "W0929 17:26:25.807962 139970483787584 deprecation_wrapper.py:119] From ../embedding_utils.py:17: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROGRESS] Starting load_train_val_data()\n",
      "[DEBUG] Loading from DATAPATH: /homes/gws/hughchen/phase/upstream_embedding/data/min5_data/SAO2minimum5/hospital_1/proc/\n",
      "[DEBUG] Loading train_x_file: X_train_60_SAO2minimum5_featnum:2_featname:ECGRATE.npy\n",
      "[DEBUG] Loading val_x_file  : X_val_60_SAO2minimum5_featnum:2_featname:ECGRATE.npy\n",
      "[DEBUG] Loading train_y_file: y_train_60_ECGRATEnextfive.npy\n",
      "[DEBUG] Loading val_y_file  : y_val_60_ECGRATEnextfive.npy\n",
      "[DEBUG] Saving processed y files\n",
      "[DEBUG] train_x.shape: (3785233, 60, 1), train_y.shape: (3785233, 5)\n",
      "[DEBUG] val_x.shape  : (420582, 60, 1),   val_y.shape: (420582, 5)\n",
      "[PROGRESS] Starting load_train_val_data()\n",
      "[DEBUG] Loading from DATAPATH: /homes/gws/hughchen/phase/upstream_embedding/data/min5_data/SAO2minimum5/hospital_1/proc/\n",
      "[DEBUG] Loading train_x_file: X_train_60_SAO2minimum5_featnum:3_featname:ETCO2.npy\n",
      "[DEBUG] Loading val_x_file  : X_val_60_SAO2minimum5_featnum:3_featname:ETCO2.npy\n",
      "[DEBUG] Loading train_y_file: y_train_60_ETCO2nextfive.npy\n",
      "[DEBUG] Loading val_y_file  : y_val_60_ETCO2nextfive.npy\n",
      "[DEBUG] Saving processed y files\n",
      "[DEBUG] train_x.shape: (3785233, 60, 1), train_y.shape: (3785233, 5)\n",
      "[DEBUG] val_x.shape  : (420582, 60, 1),   val_y.shape: (420582, 5)\n",
      "[PROGRESS] Starting load_train_val_data()\n",
      "[DEBUG] Loading from DATAPATH: /homes/gws/hughchen/phase/upstream_embedding/data/min5_data/SAO2minimum5/hospital_1/proc/\n",
      "[DEBUG] Loading train_x_file: X_train_60_SAO2minimum5_featnum:10_featname:ETSEV.npy\n",
      "[DEBUG] Loading val_x_file  : X_val_60_SAO2minimum5_featnum:10_featname:ETSEV.npy\n",
      "[DEBUG] Loading train_y_file: y_train_60_ETSEVnextfive.npy\n",
      "[DEBUG] Loading val_y_file  : y_val_60_ETSEVnextfive.npy\n",
      "[DEBUG] Saving processed y files\n",
      "[DEBUG] train_x.shape: (3785233, 60, 1), train_y.shape: (3785233, 5)\n",
      "[DEBUG] val_x.shape  : (420582, 60, 1),   val_y.shape: (420582, 5)\n",
      "[PROGRESS] Starting load_train_val_data()\n",
      "[DEBUG] Loading from DATAPATH: /homes/gws/hughchen/phase/upstream_embedding/data/min5_data/SAO2minimum5/hospital_1/proc/\n",
      "[DEBUG] Loading train_x_file: X_train_60_SAO2minimum5_featnum:9_featname:ETSEVO.npy\n",
      "[DEBUG] Loading val_x_file  : X_val_60_SAO2minimum5_featnum:9_featname:ETSEVO.npy\n",
      "[DEBUG] Loading train_y_file: y_train_60_ETSEVOnextfive.npy\n",
      "[DEBUG] Loading val_y_file  : y_val_60_ETSEVOnextfive.npy\n",
      "[DEBUG] Saving processed y files\n",
      "[DEBUG] train_x.shape: (3785233, 60, 1), train_y.shape: (3785233, 5)\n",
      "[DEBUG] val_x.shape  : (420582, 60, 1),   val_y.shape: (420582, 5)\n",
      "[PROGRESS] Starting load_train_val_data()\n",
      "[DEBUG] Loading from DATAPATH: /homes/gws/hughchen/phase/upstream_embedding/data/min5_data/SAO2minimum5/hospital_1/proc/\n",
      "[DEBUG] Loading train_x_file: X_train_60_SAO2minimum5_featnum:1_featname:FIO2.npy\n",
      "[DEBUG] Loading val_x_file  : X_val_60_SAO2minimum5_featnum:1_featname:FIO2.npy\n",
      "[DEBUG] Loading train_y_file: y_train_60_FIO2nextfive.npy\n",
      "[DEBUG] Loading val_y_file  : y_val_60_FIO2nextfive.npy\n",
      "[DEBUG] Saving processed y files\n",
      "[DEBUG] train_x.shape: (3785233, 60, 1), train_y.shape: (3785233, 5)\n",
      "[DEBUG] val_x.shape  : (420582, 60, 1),   val_y.shape: (420582, 5)\n",
      "[PROGRESS] Starting load_train_val_data()\n",
      "[DEBUG] Loading from DATAPATH: /homes/gws/hughchen/phase/upstream_embedding/data/min5_data/SAO2minimum5/hospital_1/proc/\n",
      "[DEBUG] Loading train_x_file: X_train_60_SAO2minimum5_featnum:29_featname:NIBPD.npy\n",
      "[DEBUG] Loading val_x_file  : X_val_60_SAO2minimum5_featnum:29_featname:NIBPD.npy\n",
      "[DEBUG] Loading train_y_file: y_train_60_NIBPDnextfive.npy\n",
      "[DEBUG] Loading val_y_file  : y_val_60_NIBPDnextfive.npy\n",
      "[DEBUG] Saving processed y files\n",
      "[DEBUG] train_x.shape: (3785233, 60, 1), train_y.shape: (3785233, 5)\n",
      "[DEBUG] val_x.shape  : (420582, 60, 1),   val_y.shape: (420582, 5)\n",
      "[PROGRESS] Starting load_train_val_data()\n",
      "[DEBUG] Loading from DATAPATH: /homes/gws/hughchen/phase/upstream_embedding/data/min5_data/SAO2minimum5/hospital_1/proc/\n",
      "[DEBUG] Loading train_x_file: X_train_60_SAO2minimum5_featnum:27_featname:NIBPM.npy\n",
      "[DEBUG] Loading val_x_file  : X_val_60_SAO2minimum5_featnum:27_featname:NIBPM.npy\n",
      "[DEBUG] Loading train_y_file: y_train_60_NIBPMnextfive.npy\n",
      "[DEBUG] Loading val_y_file  : y_val_60_NIBPMnextfive.npy\n",
      "[DEBUG] Saving processed y files\n",
      "[DEBUG] train_x.shape: (3785233, 60, 1), train_y.shape: (3785233, 5)\n",
      "[DEBUG] val_x.shape  : (420582, 60, 1),   val_y.shape: (420582, 5)\n",
      "[PROGRESS] Starting load_train_val_data()\n",
      "[DEBUG] Loading from DATAPATH: /homes/gws/hughchen/phase/upstream_embedding/data/min5_data/SAO2minimum5/hospital_1/proc/\n",
      "[DEBUG] Loading train_x_file: X_train_60_SAO2minimum5_featnum:28_featname:NIBPS.npy\n",
      "[DEBUG] Loading val_x_file  : X_val_60_SAO2minimum5_featnum:28_featname:NIBPS.npy\n",
      "[DEBUG] Loading train_y_file: y_train_60_NIBPSnextfive.npy\n",
      "[DEBUG] Loading val_y_file  : y_val_60_NIBPSnextfive.npy\n",
      "[DEBUG] Saving processed y files\n",
      "[DEBUG] train_x.shape: (3785233, 60, 1), train_y.shape: (3785233, 5)\n",
      "[DEBUG] val_x.shape  : (420582, 60, 1),   val_y.shape: (420582, 5)\n",
      "[PROGRESS] Starting load_train_val_data()\n",
      "[DEBUG] Loading from DATAPATH: /homes/gws/hughchen/phase/upstream_embedding/data/min5_data/SAO2minimum5/hospital_1/proc/\n",
      "[DEBUG] Loading train_x_file: X_train_60_SAO2minimum5_featnum:7_featname:PEAK.npy\n",
      "[DEBUG] Loading val_x_file  : X_val_60_SAO2minimum5_featnum:7_featname:PEAK.npy\n",
      "[DEBUG] Loading train_y_file: y_train_60_PEAKnextfive.npy\n",
      "[DEBUG] Loading val_y_file  : y_val_60_PEAKnextfive.npy\n",
      "[DEBUG] Saving processed y files\n",
      "[DEBUG] train_x.shape: (3785233, 60, 1), train_y.shape: (3785233, 5)\n",
      "[DEBUG] val_x.shape  : (420582, 60, 1),   val_y.shape: (420582, 5)\n",
      "[PROGRESS] Starting load_train_val_data()\n",
      "[DEBUG] Loading from DATAPATH: /homes/gws/hughchen/phase/upstream_embedding/data/min5_data/SAO2minimum5/hospital_1/proc/\n",
      "[DEBUG] Loading train_x_file: X_train_60_SAO2minimum5_featnum:5_featname:PEEP.npy\n",
      "[DEBUG] Loading val_x_file  : X_val_60_SAO2minimum5_featnum:5_featname:PEEP.npy\n",
      "[DEBUG] Loading train_y_file: y_train_60_PEEPnextfive.npy\n",
      "[DEBUG] Loading val_y_file  : y_val_60_PEEPnextfive.npy\n",
      "[DEBUG] Saving processed y files\n",
      "[DEBUG] train_x.shape: (3785233, 60, 1), train_y.shape: (3785233, 5)\n",
      "[DEBUG] val_x.shape  : (420582, 60, 1),   val_y.shape: (420582, 5)\n",
      "[PROGRESS] Starting load_train_val_data()\n",
      "[DEBUG] Loading from DATAPATH: /homes/gws/hughchen/phase/upstream_embedding/data/min5_data/SAO2minimum5/hospital_1/proc/\n",
      "[DEBUG] Loading train_x_file: X_train_60_SAO2minimum5_featnum:8_featname:PIP.npy\n",
      "[DEBUG] Loading val_x_file  : X_val_60_SAO2minimum5_featnum:8_featname:PIP.npy\n",
      "[DEBUG] Loading train_y_file: y_train_60_PIPnextfive.npy\n",
      "[DEBUG] Loading val_y_file  : y_val_60_PIPnextfive.npy\n",
      "[DEBUG] Saving processed y files\n",
      "[DEBUG] train_x.shape: (3785233, 60, 1), train_y.shape: (3785233, 5)\n",
      "[DEBUG] val_x.shape  : (420582, 60, 1),   val_y.shape: (420582, 5)\n",
      "[PROGRESS] Starting load_train_val_data()\n",
      "[DEBUG] Loading from DATAPATH: /homes/gws/hughchen/phase/upstream_embedding/data/min5_data/SAO2minimum5/hospital_1/proc/\n",
      "[DEBUG] Loading train_x_file: X_train_60_SAO2minimum5_featnum:4_featname:RESPRATE.npy\n",
      "[DEBUG] Loading val_x_file  : X_val_60_SAO2minimum5_featnum:4_featname:RESPRATE.npy\n",
      "[DEBUG] Loading train_y_file: y_train_60_RESPRATEnextfive.npy\n",
      "[DEBUG] Loading val_y_file  : y_val_60_RESPRATEnextfive.npy\n",
      "[DEBUG] Saving processed y files\n",
      "[DEBUG] train_x.shape: (3785233, 60, 1), train_y.shape: (3785233, 5)\n",
      "[DEBUG] val_x.shape  : (420582, 60, 1),   val_y.shape: (420582, 5)\n",
      "[PROGRESS] Starting load_train_val_data()\n",
      "[DEBUG] Loading from DATAPATH: /homes/gws/hughchen/phase/upstream_embedding/data/min5_data/SAO2minimum5/hospital_1/proc/\n",
      "[DEBUG] Loading train_x_file: X_train_60_sao2minimum5_featnum:0_featname:SAO2.npy\n",
      "[DEBUG] Loading val_x_file  : X_val_60_sao2minimum5_featnum:0_featname:SAO2.npy\n",
      "[DEBUG] Loading train_y_file: y_train_60_SAO2nextfive.npy\n",
      "[DEBUG] Loading val_y_file  : y_val_60_SAO2nextfive.npy\n",
      "[DEBUG] Saving processed y files\n",
      "[DEBUG] train_x.shape: (3785233, 60, 1), train_y.shape: (3785233, 5)\n",
      "[DEBUG] val_x.shape  : (420582, 60, 1),   val_y.shape: (420582, 5)\n",
      "[PROGRESS] Starting load_train_val_data()\n",
      "[DEBUG] Loading from DATAPATH: /homes/gws/hughchen/phase/upstream_embedding/data/min5_data/SAO2minimum5/hospital_1/proc/\n",
      "[DEBUG] Loading train_x_file: X_train_60_SAO2minimum5_featnum:11_featname:TEMP1.npy\n",
      "[DEBUG] Loading val_x_file  : X_val_60_SAO2minimum5_featnum:11_featname:TEMP1.npy\n",
      "[DEBUG] Loading train_y_file: y_train_60_TEMP1nextfive.npy\n",
      "[DEBUG] Loading val_y_file  : y_val_60_TEMP1nextfive.npy\n",
      "[DEBUG] Saving processed y files\n",
      "[DEBUG] train_x.shape: (3785233, 60, 1), train_y.shape: (3785233, 5)\n",
      "[DEBUG] val_x.shape  : (420582, 60, 1),   val_y.shape: (420582, 5)\n",
      "[PROGRESS] Starting load_train_val_data()\n",
      "[DEBUG] Loading from DATAPATH: /homes/gws/hughchen/phase/upstream_embedding/data/min5_data/SAO2minimum5/hospital_1/proc/\n",
      "[DEBUG] Loading train_x_file: X_train_60_SAO2minimum5_featnum:6_featname:TV.npy\n",
      "[DEBUG] Loading val_x_file  : X_val_60_SAO2minimum5_featnum:6_featname:TV.npy\n",
      "[DEBUG] Loading train_y_file: y_train_60_TVnextfive.npy\n",
      "[DEBUG] Loading val_y_file  : y_val_60_TVnextfive.npy\n",
      "[DEBUG] Saving processed y files\n",
      "[DEBUG] train_x.shape: (3785233, 60, 1), train_y.shape: (3785233, 5)\n",
      "[DEBUG] val_x.shape  : (420582, 60, 1),   val_y.shape: (420582, 5)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from phase.embedding import *\n",
    "\n",
    "PATH = os.path.expanduser(\"~/phase/upstream_embedding/\")\n",
    "\n",
    "for hosp_data in [0,1]:\n",
    "    DATAPATH  = '{}data/min5_data/{}minimum5/hospital_{}/proc/'.format(PATH,\"SAO2\",hosp_data)\n",
    "    task = \"nextfive\"\n",
    "    # task = \"minimum5\"\n",
    "    # task = \"hypo\"\n",
    "\n",
    "    ########## Form Data #########\n",
    "    X_train_lst = []; X_valid_lst = []\n",
    "    y_train_lst = []; y_valid_lst = []\n",
    "\n",
    "    for i in range(0,len(X_lst)):\n",
    "        feat = X_lst[i]\n",
    "\n",
    "        data = load_train_val_data(DATAPATH,task,feat=feat,save_proc_y=True,\n",
    "                                   filter_zeros=False,impute_per_sample=False)\n",
    "        X_train, y_train, X_valid, y_valid = data\n",
    "\n",
    "        X_train_lst.append(X_train)\n",
    "        X_valid_lst.append(X_valid)\n",
    "        y_train_lst.append(y_train)\n",
    "        y_valid_lst.append(y_valid)\n",
    "        \n",
    "    opt_name=\"rmsprop\";lr=0.001;drop=0.5\n",
    "    b_size=1000;epoch_num=200;nodesize=200\n",
    "    per_epoch_size = 300000\n",
    "\n",
    "    # Fixed hyperpara\n",
    "    print(\"[PROGRESS] Starting create_train_model()\")\n",
    "    h1 = nodesize; h2 = nodesize\n",
    "    lookback = 60; loss_func = \"mse\"\n",
    "\n",
    "    # Set opt based on opt_name\n",
    "    if opt_name is \"rmsprop\":\n",
    "        opt = keras.optimizers.RMSprop(lr)\n",
    "    elif opt_name is \"sgd\":\n",
    "        opt = keras.optimizers.SGD(lr)\n",
    "    elif opt_name is \"adam\":\n",
    "        opt = keras.optimizers.Adam(lr)\n",
    "\n",
    "    # Form the model name (for saving the model)\n",
    "    mod_name  = \"multivariate_biglstmdropout_hd{}_\".format(hosp_data)\n",
    "    mod_name += \"{}task_{}n_{}n_{}ep\".format(task,h1,h2,epoch_num)\n",
    "    mod_name += \"_{}opt_{}lr\".format(opt_name,lr)\n",
    "    mod_name += \"_{}drop_{}bs_epochsize\".format(drop,b_size,per_epoch_size)\n",
    "    MODDIR = PATH+\"models/\"+mod_name+\"/\"\n",
    "\n",
    "    loss_keys = [\"loss\", 'val_loss']\n",
    "    [loss_keys.append(\"val_dense_{}_loss\".format(i)) for i in range(1,16)]\n",
    "\n",
    "    if not os.path.exists(MODDIR): \n",
    "        os.makedirs(MODDIR)\n",
    "        with open(MODDIR+\"loss.txt\", \"w\") as f:\n",
    "            f.write(\"\\t\".join([\"i\", \"epoch_time\"] + loss_keys)+\"\\n\")\n",
    "\n",
    "        ########## Form Model #########\n",
    "        sig_lst     = []; encoded_lst = []\n",
    "        for i in range(0,len(X_lst)):\n",
    "            sig = Input(shape=(lookback,1))\n",
    "            lstm1 = LSTM(h1, recurrent_dropout=drop, return_sequences=True)\n",
    "            lstm2 = LSTM(h2, recurrent_dropout=drop, dropout=drop)\n",
    "\n",
    "            encoded = lstm2(lstm1(sig))\n",
    "            sig_lst.append(sig); encoded_lst.append(encoded)\n",
    "        merged_vector = keras.layers.concatenate(encoded_lst, axis=-1)\n",
    "\n",
    "        prediction_lst = []\n",
    "        for i in range(0,len(X_lst)):\n",
    "            prediction = Dense(5, activation='sigmoid')(merged_vector)\n",
    "            prediction_lst.append(prediction)\n",
    "\n",
    "        model = Model(inputs=sig_lst, outputs=prediction_lst)\n",
    "        model = multi_gpu_model(model,gpus=GPUNUM)\n",
    "        model.compile(optimizer=opt, loss=loss_func)\n",
    "\n",
    "        ########## Training #########\n",
    "        print(\"[PROGRESS] Starting train_model()\")\n",
    "\n",
    "        # Train and Save\n",
    "        start_time = time.time()\n",
    "        for i in range(0,epoch_num):\n",
    "            train_subset_inds = np.random.choice(X_train_lst[0].shape[0],per_epoch_size,replace=False)\n",
    "            X_train_lst_sub = [X[train_subset_inds] for X in X_train_lst]\n",
    "            y_train_lst_sub = [y[train_subset_inds] for y in y_train_lst]\n",
    "            history = model.fit(X_train_lst_sub, y_train_lst_sub, epochs=1, batch_size=b_size, \n",
    "                                validation_data=(X_valid_lst,y_valid_lst))\n",
    "\n",
    "            # Save details about training\n",
    "            epoch_time = time.time() - start_time\n",
    "            write_lst = [i, epoch_time]\n",
    "            write_lst += [history.history[k][0] for k in loss_keys]\n",
    "            with open(MODDIR+\"loss.txt\", \"a\") as f:\n",
    "                f.write(\"\\t\".join([str(round(e,5)) for e in write_lst])+\"\\n\")\n",
    "\n",
    "            # Save model each iteration\n",
    "            val_loss = history.history['val_loss'][0]\n",
    "            model.save(\"{}val_loss:{}_epoch:{}_{}.h5\".format(MODDIR,val_loss,i,mod_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf36)",
   "language": "python",
   "name": "tf36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
