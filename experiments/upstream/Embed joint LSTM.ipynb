{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed data with joint LSTM\n",
    "\n",
    "Embed the downstream data using the joint LSTM trained on all signals simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed the downstream prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0213 09:45:03.707623 140235354949440 deprecation_wrapper.py:119] From ../embedding_utils.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0213 09:45:03.709717 140235354949440 deprecation_wrapper.py:119] From ../embedding_utils.py:16: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "W0213 09:45:03.711277 140235354949440 deprecation_wrapper.py:119] From ../embedding_utils.py:17: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,7\"\n",
    "import sys\n",
    "sys.path.insert(0,\"..\")\n",
    "from embedding_utils import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate embeddings for nextfivemulti etco2 hosp_model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Progress] label_type: etco235, eta: NA, curr_feat ETCO2\n",
      "[PROGRESS] Starting load_min_model_helper()\n",
      "[DEBUG] MPATH /homes/gws/hughchen/phase/upstream_embedding/models/multivariate_biglstmdropout_hd1_nextfivetask_200n_200n_200ep_rmspropopt_0.001lr_0.5drop_1000bs_epochsize\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0213 09:45:15.100636 140235354949440 deprecation_wrapper.py:119] From /homes/gws/hughchen/anaconda2/envs/tf36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0213 09:45:15.184010 140235354949440 deprecation_wrapper.py:119] From /homes/gws/hughchen/anaconda2/envs/tf36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] min_mod_name val_loss:10.944383427112342_epoch:177_multivariate_biglstmdropout_hd1_nextfivetask_200n_200n_200ep_rmspropopt_0.001lr_0.5drop_1000bs_epochsize.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0213 09:45:15.612288 140235354949440 deprecation.py:506] From /homes/gws/hughchen/anaconda2/envs/tf36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0213 09:45:59.127630 140235354949440 deprecation_wrapper.py:119] From /homes/gws/hughchen/anaconda2/envs/tf36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0213 09:46:04.730756 140235354949440 deprecation.py:323] From /homes/gws/hughchen/anaconda2/envs/tf36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Progress] hosp_data 1\n",
      "\n",
      "[Progress] data_type proc[top15]+nonsignal\n",
      "[DEBUG] Starting load_raw_data\n",
      "[DEBUG] DPATH /homes/gws/hughchen/phase/downstream_prediction//data/etco235/hospital_1/\n",
      "[DEBUG] Starting load_raw_data\n",
      "[DEBUG] DPATH /homes/gws/hughchen/phase/downstream_prediction//data/etco235/hospital_1/\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from xgb_setup import *\n",
    "os.nice(5)\n",
    "# PATH = \"/projects/leelab2/hughchen/RELIC/repr_learning/\"\n",
    "PATH = \"/homes/gws/hughchen/phase/downstream_prediction/\"\n",
    "RESULTPATH = PATH+\"/results/\"; MODELPATH = PATH+\"/models/\"\n",
    "lookback = 60\n",
    "DEBUG = False\n",
    "\n",
    "label_type_eta_currfeat_lst = [(\"etco235\",0.1,\"ETCO2\")]\n",
    "\n",
    "for label_type, _, curr_feat in label_type_eta_currfeat_lst:\n",
    "    print(\"\\n[Progress] label_type: {}, eta: {}, curr_feat {}\".format(label_type, \"NA\", curr_feat))\n",
    "\n",
    "    mod_type = \"lstmarms_{}_top15\".format(label_type)\n",
    "    RESDIR = '{}{}/'.format(RESULTPATH, mod_type)\n",
    "    if not os.path.exists(RESDIR): os.makedirs(RESDIR)\n",
    "\n",
    "    for hosp_model in [1]:\n",
    "\n",
    "        # This is the order of features that the big LSTM uses\n",
    "        top15 = [\"SAO2\",\"FIO2\",\"ECGRATE\",\"ETCO2\",\"RESPRATE\",\"PEEP\",\"TV\",\"PEAK\",\n",
    "                 \"PIP\",\"ETSEVO\",\"ETSEV\",\"TEMP1\",\"NIBPM\",\"NIBPS\",\"NIBPD\"]\n",
    "\n",
    "        MODDIR = \"/homes/gws/hughchen/phase/upstream_embedding/models/\"\n",
    "        MODDIR += \"multivariate_biglstmdropout_hd{}_nextfivetask_\".format(hosp_model)\n",
    "        MODDIR += \"200n_200n_200ep_rmspropopt_0.001lr_0.5drop_1000bs_epochsize\"\n",
    "        min_mod = load_min_model_helper(MODDIR)\n",
    "        min_mod_weights = min_mod.get_weights()\n",
    "\n",
    "        for hosp_data in [1]:\n",
    "            print(\"\\n[Progress] hosp_data {}\".format(hosp_data))\n",
    "\n",
    "            data_type = \"proc[top15]+nonsignal\"\n",
    "\n",
    "            print(\"\\n[Progress] data_type {}\".format(data_type))\n",
    "            # Load train validation data and split it\n",
    "            (X_trval_lst,y_trval) = load_data(PATH,data_type,label_type,True,hosp_data,curr_feat,DEBUG=DEBUG)\n",
    "            X_trval_lst = [X[:,:,np.newaxis] if X.shape[1] == 60 else X for X in X_trval_lst]\n",
    "            \n",
    "            # Load test data\n",
    "            (X_test1_lst,y_test1) = load_data(PATH,data_type,label_type,False,hosp_data,curr_feat,DEBUG=DEBUG)\n",
    "            X_test1_lst = [X[:,:,np.newaxis] if X.shape[1] == 60 else X for X in X_test1_lst]\n",
    "            \n",
    "            # Create and save embeddings for top15 features\n",
    "            task = \"nextfivemulti\"\n",
    "            suffix = \"embedding_data{}_model{}.npy\".format(hosp_data,hosp_model)\n",
    "            final_task = label_type\n",
    "            SPATH = PATH+\"data/{}/hospital_{}/hidden200/{}/model_{}/\".format(final_task,hosp_data,task,hosp_model)\n",
    "            if not os.path.exists(SPATH): os.makedirs(SPATH)\n",
    "\n",
    "            for i in range(0,len(top15)):\n",
    "                feat = top15[i] # Current feature being embedded\n",
    "                \n",
    "                # Create model\n",
    "                h1 = 200; h2 = 200; lookback = 60\n",
    "                model = Sequential()\n",
    "                model.add(LSTM(h1, recurrent_dropout=0.5, return_sequences=True, input_shape=(lookback,1), \n",
    "                                weights=min_mod_weights[(i*3):((i+1)*3)]))\n",
    "                model.add(LSTM(h2, recurrent_dropout=0.5,dropout=0.5,\n",
    "                               weights=min_mod_weights[(45+(i*3)):(45+((i+1)*3))]))\n",
    "\n",
    "                # Create embeddings and names\n",
    "                trval_pred = model.predict(X_trval_lst[i])\n",
    "                test1_pred = model.predict(X_test1_lst[i])\n",
    "                trval_pred_name = \"task:{}_feat:{}_trval_{}\".format(task,feat,suffix)\n",
    "                test1_pred_name = \"task:{}_feat:{}_test1_{}\".format(task,feat,suffix)\n",
    "\n",
    "                # Save embeddings\n",
    "                np.save(SPATH+trval_pred_name,trval_pred)\n",
    "                np.save(SPATH+test1_pred_name,test1_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf36)",
   "language": "python",
   "name": "tf36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
