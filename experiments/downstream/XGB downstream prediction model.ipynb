{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downstream prediction using XGB\n",
    "\n",
    "Perform downstream predictions using different embeddings.  Goal is to investigate the efficacy of the LSTM XGB pipeline in addition to comparing the self-supervised embedding outcomes (next and min) to the unsupervised (auto) and the supervised outcomes (hypo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phase import prediction\n",
    "\n",
    "os.nice(5)\n",
    "PATH = \"/projects/leelab2/hughchen/RELIC/repr_learning\"\n",
    "DPATH = \"/homes/gws/hughchen/phase/downstream_prediction/\"\n",
    "RESULTPATH = PATH+\"/results/\"; MODELPATH = PATH+\"/models/\"\n",
    "lookback = 60\n",
    "DEBUG = False\n",
    "\n",
    "label_type_eta_currfeat_lst = [(\"desat_bool92_5_nodesat\",0.02,\"SAO2\"),(\"nibpm60\",0.1,\"NIBPM\"), (\"etco235\",0.1,\"ETCO2\")]\n",
    "\n",
    "for label_type, eta, curr_feat in label_type_eta_currfeat_lst:\n",
    "    print(\"\\n[Progress] label_type: {}, eta: {}, curr_feat {}\".format(label_type, eta, curr_feat))\n",
    "\n",
    "    xgb_type = \"xgb_{}_top15_eta{}\".format(label_type,eta)\n",
    "    RESDIR = '{}{}/'.format(RESULTPATH, xgb_type)\n",
    "    if not os.path.exists(RESDIR): os.makedirs(RESDIR)\n",
    "\n",
    "    for hosp_data in [0,1]:\n",
    "        print(\"\\n[Progress] hosp_data {}\".format(hosp_data))\n",
    "        dt_lst = [\"raw[top15]+nonsignal\",\n",
    "                  \"ema[top15]+nonsignal\",\n",
    "                  \"randemb[top15]+nonsignal\"]\n",
    "\n",
    "        for hosp_model in [0,1]:\n",
    "            print(\"\\n[Progress] hosp_model {}\".format(hosp_model))\n",
    "            dt_lst += [\"nextfive_{}[top15]+nonsignal\".format(hosp_model),\n",
    "                       \"auto_{}[top15]+nonsignal\".format(hosp_model),\n",
    "                       \"min5_{}[top15]+nonsignal\".format(hosp_model)]\n",
    "            \n",
    "            if \"desat\" in label_type:\n",
    "                dt_lst += [\"hypox_{}[top15]+nonsignal\".format(hosp_model)]\n",
    "            elif \"nibpm\" in label_type:\n",
    "                dt_lst += [\"hypot_{}[top15]+nonsignal\".format(hosp_model)]\n",
    "            elif \"etco2\" in label_type:\n",
    "                dt_lst += [\"hypoc_{}[top15]+nonsignal\".format(hosp_model)]\n",
    "                \n",
    "            for data_type in dt_lst:\n",
    "                print(\"\\n[Progress] data_type {}\".format(data_type))\n",
    "\n",
    "                (trainvalX,trainvalY) = load_data(DPATH,data_type,label_type,True,hosp_data,curr_feat,DEBUG=DEBUG)\n",
    "                print(\"[Progress] trainvalX.shape {}\".format(trainvalX.shape))\n",
    "                if not DEBUG:\n",
    "                    train_xgb_model(RESDIR,trainvalX,trainvalY,\"200epochs_\"+data_type,label_type,hosp_data,eta)\n",
    "\n",
    "                (test1X,test1Y)       = load_data(DPATH,data_type,label_type,False,hosp_data,curr_feat,DEBUG=DEBUG)\n",
    "                print(\"[Progress] test1X.shape    {}\".format(test1X.shape))\n",
    "                if not DEBUG:\n",
    "                    load_xgb_model_and_test(RESDIR,test1X,test1Y,\"200epochs_\"+data_type,label_type,hosp_data,xgb_type,eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run xgb on the phenylephrine and hypertension data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from xgb_setup import *\n",
    "os.nice(5)\n",
    "PATH = \"/projects/leelab2/hughchen/RELIC/repr_learning\"\n",
    "DPATH = \"/homes/gws/hughchen/phase/downstream_prediction/\"\n",
    "RESULTPATH = PATH+\"/results/\"; MODELPATH = PATH+\"/models/\"\n",
    "lookback = 60\n",
    "DEBUG = False\n",
    "\n",
    "label_type_eta_currfeat_lst = [(\"nibpm110\",0.1,\"NIBPM\"), (\"med_phenyl\",0.1,\"NIBPM\")]\n",
    "\n",
    "for label_type, eta, curr_feat in label_type_eta_currfeat_lst:\n",
    "    print(\"\\n*[Progress] label_type: {}, eta: {}, curr_feat {}\".format(label_type, eta, curr_feat))\n",
    "\n",
    "    xgb_type = \"xgb_{}_top15_eta{}\".format(label_type,eta)\n",
    "    RESDIR = '{}{}/'.format(RESULTPATH, xgb_type)\n",
    "    if not os.path.exists(RESDIR): os.makedirs(RESDIR)\n",
    "\n",
    "    for hosp_data in [0,1]:\n",
    "        print(\"\\n***[Progress] hosp_data {}\".format(hosp_data))\n",
    "\n",
    "        dt_lst = [\"randemb[top15]+nonsignal\"]\n",
    "\n",
    "        for hosp_model in [0,1]:\n",
    "            dt_lst += [\"nextfive_{}[top15]+nonsignal\".format(hosp_model),\n",
    "                       \"auto_{}[top15]+nonsignal\".format(hosp_model),\n",
    "                       \"min5_{}[top15]+nonsignal\".format(hosp_model)]\n",
    "\n",
    "        for data_type in dt_lst:\n",
    "            print(\"\\n*****[Progress] data_type {}\".format(data_type))\n",
    "\n",
    "            (trainvalX,trainvalY) = load_data(DPATH,data_type,label_type,True,hosp_data,curr_feat,DEBUG=DEBUG)\n",
    "            print(\"[Progress] trainvalX.shape {}\".format(trainvalX.shape))\n",
    "            if not DEBUG:\n",
    "                train_xgb_model(RESDIR,trainvalX,trainvalY2,\"200epochs_\"+data_type,label_type,hosp_data,eta)\n",
    "\n",
    "            (test1X,test1Y)       = load_data(DPATH,data_type,label_type,False,hosp_data,curr_feat,DEBUG=DEBUG)\n",
    "            print(\"[Progress] test1X.shape    {}\".format(test1X.shape))\n",
    "            if not DEBUG:\n",
    "                load_xgb_model_and_test(RESDIR,test1X,test1Y2,\"200epochs_\"+data_type,label_type,hosp_data,xgb_type,eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run XGB on the nextfivemulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Progress] label_type: desat_bool92_5_nodesat, eta: 0.02, curr_feat SAO2\n",
      "\n",
      "[Progress] hosp_data 0\n",
      "\n",
      "[Progress] hosp_model 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dt_lst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-927e62571d11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhosp_model\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n[Progress] hosp_model {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhosp_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mdt_lst\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"nextfivemulti_{}[top15]+nonsignal\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhosp_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdata_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdt_lst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dt_lst' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from xgb_setup import *\n",
    "os.nice(5)\n",
    "PATH = \"/projects/leelab2/hughchen/RELIC/repr_learning\"\n",
    "DPATH = \"/homes/gws/hughchen/phase/downstream_prediction/\"\n",
    "RESULTPATH = PATH+\"/results/\"; MODELPATH = PATH+\"/models/\"\n",
    "lookback = 60\n",
    "DEBUG = False\n",
    "\n",
    "label_type_eta_currfeat_lst = [(\"desat_bool92_5_nodesat\",0.02,\"SAO2\"),(\"etco235\",0.1,\"ETCO2\")]\n",
    "\n",
    "for label_type, eta, curr_feat in label_type_eta_currfeat_lst:\n",
    "    print(\"\\n[Progress] label_type: {}, eta: {}, curr_feat {}\".format(label_type, eta, curr_feat))\n",
    "\n",
    "    xgb_type = \"xgb_{}_top15_eta{}\".format(label_type,eta)\n",
    "    RESDIR = '{}{}/'.format(RESULTPATH, xgb_type)\n",
    "    if not os.path.exists(RESDIR): os.makedirs(RESDIR)\n",
    "\n",
    "    for hosp_data in [0,1]:\n",
    "        print(\"\\n[Progress] hosp_data {}\".format(hosp_data))\n",
    "\n",
    "        for hosp_model in [0,1]:\n",
    "            print(\"\\n[Progress] hosp_model {}\".format(hosp_model))\n",
    "            dt_lst = [\"nextfivemulti_{}[top15]+nonsignal\".format(hosp_model)]\n",
    "            \n",
    "            for data_type in dt_lst:\n",
    "                print(\"\\n[Progress] data_type {}\".format(data_type))\n",
    "\n",
    "                (trainvalX,trainvalY) = load_data(DPATH,data_type,label_type,True,hosp_data,curr_feat,DEBUG=DEBUG)\n",
    "                print(\"[Progress] trainvalX.shape {}\".format(trainvalX.shape))\n",
    "                if not DEBUG:\n",
    "                    train_xgb_model(RESDIR,trainvalX,trainvalY,\"200epochs_\"+data_type,label_type,hosp_data,eta)\n",
    "\n",
    "                (test1X,test1Y)       = load_data(DPATH,data_type,label_type,False,hosp_data,curr_feat,DEBUG=DEBUG)\n",
    "                print(\"[Progress] test1X.shape    {}\".format(test1X.shape))\n",
    "                if not DEBUG:\n",
    "                    load_xgb_model_and_test(RESDIR,test1X,test1Y,\"200epochs_\"+data_type,label_type,hosp_data,xgb_type,eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf36)",
   "language": "python",
   "name": "tf36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
