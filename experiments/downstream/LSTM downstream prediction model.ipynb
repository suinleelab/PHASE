{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM downstream prediction model\n",
    "\n",
    "Evaluate an LSTM downstream prediction model on the raw physiological signal embeddings and the static patient data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from phase.prediction import *\n",
    "\n",
    "PATH  = os.path.expanduser(\"~/phase/\")\n",
    "DPATH = PATH+\"downstream_prediction/\"\n",
    "RESULTPATH = PATH+\"/results/\"\n",
    "MODELPATH  = PATH+\"/models/\"\n",
    "\n",
    "lookback = 60\n",
    "DEBUG = False\n",
    "\n",
    "label_type = \"desat_bool92_5_nodesat\"\n",
    "curr_feat = \"SAO2\"\n",
    "print(\"\\n[Progress] label_type: {}, curr_feat {}\".format(label_type, curr_feat))\n",
    "\n",
    "hosp_data = 0\n",
    "data_type = \"proc[top15]+nonsignal\"\n",
    "\n",
    "# Load train validation data and split it\n",
    "(X_trval_lst,y_trval) = load_data(DPATH,data_type,label_type,True,\n",
    "                                  hosp_data,curr_feat,DEBUG=DEBUG)\n",
    "X_trval_lst = standardize_static(X_trval_lst)\n",
    "\n",
    "numlayers = [1,2,3]\n",
    "numnodes  = [100,200,300]\n",
    "opt_lst   = [\"RMSprop\", \"SGD\", \"Adam\"]\n",
    "lr_lst    = [0.01,0.001,0.0001]\n",
    "drop_lst  = [0,0.5]\n",
    "\n",
    "for numlayer in numlayers:\n",
    "    for numnode in numnodes:\n",
    "        for opt in opt_lst[0:1]:\n",
    "            for lr in lr_lst:\n",
    "                for drop in drop_lst:\n",
    "                    hyper_dict = {\"numlayer\":numlayer,\"numnode\":numnode,\n",
    "                                  \"opt\":opt,\"lr\":lr,\"drop\":drop}\n",
    "                    form_train_model(X_trval_lst,y_trval,hyper_dict,label_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load min model and train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Progress] label_type: desat_bool92_5_nodesat, curr_feat SAO2\n",
      "[DEBUG] Y.shape: (3920564,)\n",
      "[DEBUG] Starting load_raw_data\n",
      "[DEBUG] DPATH /homes/gws/hughchen/phase/downstream_prediction//data/desat_bool92_5_nodesat/hospital_0/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1028 09:03:05.937915 140596101756736 deprecation_wrapper.py:119] From /homes/gws/hughchen/anaconda2/envs/tf36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1028 09:03:05.939880 140596101756736 deprecation_wrapper.py:119] From /homes/gws/hughchen/anaconda2/envs/tf36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1028 09:03:05.943795 140596101756736 deprecation_wrapper.py:119] From /homes/gws/hughchen/anaconda2/envs/tf36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROGRESS] form_model()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1028 09:03:19.665680 140596101756736 deprecation_wrapper.py:119] From /homes/gws/hughchen/anaconda2/envs/tf36/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1028 09:03:19.672633 140596101756736 deprecation_wrapper.py:119] From /homes/gws/hughchen/anaconda2/envs/tf36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W1028 09:03:19.677962 140596101756736 deprecation.py:323] From /homes/gws/hughchen/anaconda2/envs/tf36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PROGRESS] Starting train_model()\n",
      "[PROGRESS] Making MODDIR /homes/gws/hughchen/phase/downstream_prediction/models/multilstm_0hospdata_desat_bool92_5_nodesatlabel_3numlayer_300numnode_RMSpropopt_0.001lr_0.0drop_1000bsize_200epochnum_300000perepochsize/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1028 09:03:23.311719 140596101756736 deprecation_wrapper.py:119] From /homes/gws/hughchen/anaconda2/envs/tf36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300000 samples, validate on 392057 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 171s 570us/step - loss: 0.0550 - val_loss: 0.0437\n",
      "Train on 300000 samples, validate on 392057 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 166s 554us/step - loss: 0.0449 - val_loss: 0.0410\n",
      "Train on 300000 samples, validate on 392057 samples\n",
      "Epoch 1/1\n",
      "300000/300000 [==============================] - 166s 552us/step - loss: 0.0407 - val_loss: 0.0396\n",
      "Train on 300000 samples, validate on 392057 samples\n",
      "Epoch 1/1\n",
      "299000/300000 [============================>.] - ETA: 0s - loss: 0.0412"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from phase.prediction import *\n",
    "\n",
    "PATH  = os.path.expanduser(\"~/phase/\")\n",
    "DPATH = PATH+\"downstream_prediction/\"\n",
    "RESULTPATH = PATH+\"/results/\"\n",
    "MODELPATH  = PATH+\"/models/\"\n",
    "\n",
    "lookback = 60\n",
    "DEBUG = False\n",
    "\n",
    "label_type_eta_currfeat_lst = [(\"desat_bool92_5_nodesat\",0.02,\"SAO2\"),\n",
    "                               (\"nibpm60\",0.1,\"NIBPM\"), \n",
    "                               (\"etco235\",0.1,\"ETCO2\")]\n",
    "\n",
    "for label_type, _, curr_feat in label_type_eta_currfeat_lst:\n",
    "    print(\"\\n[Progress] label_type: {}, curr_feat {}\".format(label_type, curr_feat))\n",
    "\n",
    "    hosp_data = 0\n",
    "    data_type = \"proc[top15]+nonsignal\"\n",
    "\n",
    "    # Get best model in terms of min validation loss\n",
    "    TUNEPATH = MODELPATH+\"tune_multilstm_0hospdata_desat_bool92_5_nodesatlabel/\"\n",
    "    mod_names = os.listdir(TUNEPATH)\n",
    "    best_min_val_loss = float(\"inf\")\n",
    "    for mod_name in mod_names:\n",
    "        CURRMODPATH = TUNEPATH+mod_name\n",
    "        model_checkpts = [f for f in os.listdir(CURRMODPATH) if \"val_loss\" in f]\n",
    "        min_val_loss = float(sorted(model_checkpts)[1].split(\"val_loss:\")[1].split(\"_\")[0])\n",
    "        if min_val_loss < best_min_val_loss:\n",
    "            best_min_val_loss = min_val_loss\n",
    "            best_mod_name = mod_name\n",
    "\n",
    "    hyper_dict = {\"numlayer\" : int(best_mod_name.split(\"numlayer_\")[0]),\n",
    "                  \"numnode\"  : int(best_mod_name.split(\"numnode_\")[0].split(\"_\")[-1]),\n",
    "                  \"opt\"      : best_mod_name.split(\"opt_\")[0].split(\"_\")[-1],\n",
    "                  \"lr\"       : float(best_mod_name.split(\"lr_\")[0].split(\"_\")[-1]),\n",
    "                  \"drop\"     : float(best_mod_name.split(\"drop_\")[0].split(\"_\")[-1])}\n",
    "\n",
    "    # Load train validation data and split it\n",
    "    (X_trval_lst,y_trval) = load_data(DPATH,data_type,label_type,True,hosp_data,curr_feat,DEBUG=DEBUG)\n",
    "    X_trval_lst = standardize_static(X_trval_lst)\n",
    "\n",
    "    # Train model\n",
    "    MODDIR = form_train_model(X_trval_lst,y_trval,hyper_dict,label_type,is_tune=False,epoch_num=200)\n",
    "\n",
    "    mod_type = \"multilstm_{}\".format(label_type)\n",
    "    RESDIR = '{}{}/'.format(RESULTPATH, mod_type)\n",
    "    if not os.path.exists(RESDIR): os.makedirs(RESDIR)\n",
    "\n",
    "    # Load test data\n",
    "    (X_test1_lst,y_test1) = load_data(DPATH,data_type,label_type,False,hosp_data,curr_feat,DEBUG=DEBUG)\n",
    "    X_test1_lst = standardize_static(X_test1_lst)\n",
    "    X_test1_lst = [X[:,:,np.newaxis] if X.shape[1] == 60 else X for X in X_test1_lst]\n",
    "    X_test1_lst = [np.concatenate(X_test1_lst[:-1],2),X_test1_lst[-1]]\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    load_model_and_test(RESDIR,MODDIR,X_test1_lst,y_test,data_type,hosp_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
